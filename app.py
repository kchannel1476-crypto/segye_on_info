import os
import base64
import tempfile
import shutil
from pathlib import Path
from typing import Any, Dict, List, Optional
from urllib.parse import urlparse
import time
import re
import streamlit as st
import json


def xml_escape(s: str) -> str:
    if s is None:
        return ""
    s = str(s)
    # XMLì—ì„œ ê¹¨ì§€ëŠ” ì œì–´ë¬¸ì ì œê±° (íƒ­/ê°œí–‰ì€ í—ˆìš©)
    s = re.sub(r"[\x00-\x08\x0B\x0C\x0E-\x1F]", "", s)
    s = (
        s.replace("&", "&amp;")
        .replace("<", "&lt;")
        .replace(">", "&gt;")
        .replace('"', "&quot;")
        .replace("'", "&apos;")
    )
    return s


def sanitize_svg_for_png(svg: str) -> str:
    if not svg:
        return ""
    svg = svg.replace("\ufeff", "")
    svg = re.sub(r"[\x00-\x08\x0B\x0C\x0E-\x1F]", "", svg)
    svg = re.sub(r"^\s*<\?xml[^>]*\?>\s*", "", svg)
    return svg


def strip_svg_imports(svg: str) -> str:
    """SVG ë¬¸ìì—´ì—ì„œ @import url(...); ì œê±° (ì¼ë¶€ ë Œë”ëŸ¬ í˜¸í™˜ìš©)."""
    if not svg:
        return ""
    return re.sub(r"@import\s+url\([^;]+;\s*", "", svg)


def strip_css_import(svg: str) -> str:
    """SVGì—ì„œ @import url(...); ì œê±°."""
    if not svg:
        return ""
    return re.sub(r"@import\s+url\([^)]*\);\s*", "", svg)


def _font_file_uri(path: str) -> str:
    """ì ˆëŒ€ ê²½ë¡œë¥¼ file:// URIë¡œ (cairosvgê°€ ë¡œì»¬ í°íŠ¸ ë¡œë“œí•˜ë„ë¡)."""
    try:
        from pathlib import Path
        return Path(os.path.abspath(path)).as_uri()
    except Exception:
        return ""


# PNG í•œê¸€ í°íŠ¸ ê²€ìƒ‰ ê²½ë¡œ (í”„ë¡œì íŠ¸ fonts/ â†’ SEGYE_FONTS_DIR â†’ ì•„ë˜ ê²½ë¡œ ìˆœ)
_FONTS_FALLBACK_DIRS = [
    os.path.join(os.path.dirname(os.path.abspath(__file__)), "fonts"),
    os.environ.get("SEGYE_FONTS_DIR", "").strip() or None,
    os.path.expanduser(r"~\Desktop\static"),
    r"c:\Users\segye\Desktop\static",
]


def _find_font_path(filename: str) -> str:
    """NotoSansKR-*.ttf íŒŒì¼ì„ ê²€ìƒ‰ ê²½ë¡œì—ì„œ ì°¾ì•„ ì ˆëŒ€ ê²½ë¡œ ë°˜í™˜."""
    for d in _FONTS_FALLBACK_DIRS:
        if not d or not os.path.isdir(d):
            continue
        path = os.path.join(d, filename)
        if os.path.isfile(path):
            return path
    return ""


def _prepare_fonts_for_png() -> tuple[str, str]:
    """
    PNG ë³€í™˜ìš© í°íŠ¸ file:// URI ë°˜í™˜.
    TTFë¥¼ ì„ì‹œ ë””ë ‰í„°ë¦¬ì— ë³µì‚¬í•´ ì§§ì€ ê²½ë¡œì˜ file:// ë¡œ ì”€ (cairosvgëŠ” base64 ë¯¸ì§€ì›, file:// ì‹œë„).
    ë°˜í™˜: (uri_regular, uri_bold)
    """
    uri_r, uri_b = "", ""
    try:
        tmp = tempfile.mkdtemp(prefix="segye_fonts_")
        for name in ("NotoSansKR-Regular.ttf", "NotoSansKR-Bold.ttf"):
            src = _find_font_path(name)
            if not src or not os.path.isfile(src):
                continue
            dst = os.path.join(tmp, name)
            shutil.copy2(src, dst)
            uri = Path(dst).resolve().as_uri()
            if "Regular" in name:
                uri_r = uri
            else:
                uri_b = uri
        # ì„ì‹œ í´ë”ëŠ” í”„ë¡œì„¸ìŠ¤ ì¢…ë£Œ ì‹œ ì •ë¦¬ë˜ë„ë¡ ë‘  (ë˜ëŠ” atexitë¡œ ì‚­ì œ ê°€ëŠ¥)
    except Exception:
        pass
    return (uri_r, uri_b)


def svg_fonts_to_absolute_paths(svg: str) -> str:
    """
    PNG ë³€í™˜ ì‹œ í•œê¸€ í°íŠ¸ê°€ ì ìš©ë˜ë„ë¡ SVGì˜ í°íŠ¸ URLì„ file:// ì ˆëŒ€ ê²½ë¡œë¡œ ì¹˜í™˜.
    cairosvgëŠ” base64 @font-faceë¥¼ ì§€ì›í•˜ì§€ ì•Šìœ¼ë¯€ë¡œ, TTFë¥¼ ì„ì‹œ í´ë”ì— ë³µì‚¬í•œ file:// ì‚¬ìš©.
    """
    if not svg:
        return svg
    uri_regular, uri_bold = _prepare_fonts_for_png()
    out = svg
    if uri_regular:
        out = out.replace('url("fonts/NotoSansKR-Regular.ttf")', f'url("{uri_regular}")')
        out = out.replace("url('fonts/NotoSansKR-Regular.ttf')", f'url("{uri_regular}")')
        out = re.sub(
            r'url\("data:font/ttf;base64,[^"]+"\)(?=\s*format\(\'truetype\'\)\s*;\s*font-weight:\s*400)',
            f'url("{uri_regular}")',
            out,
            count=1,
        )
    if uri_bold:
        out = out.replace('url("fonts/NotoSansKR-Bold.ttf")', f'url("{uri_bold}")')
        out = out.replace("url('fonts/NotoSansKR-Bold.ttf')", f'url("{uri_bold}")')
        out = re.sub(
            r'url\("data:font/ttf;base64,[^"]+"\)(?=\s*format\(\'truetype\'\)\s*;\s*font-weight:\s*700)',
            f'url("{uri_bold}")',
            out,
            count=1,
        )
    return out


def get_openai_client():
    try:
        from openai import OpenAI
    except Exception:
        return None
    key = None
    try:
        key = st.secrets.get("OPENAI_API_KEY")
    except Exception:
        pass
    key = key or os.getenv("OPENAI_API_KEY")
    if not key:
        return None
    return OpenAI(api_key=key)


def _safe_json_loads(s: str):
    """JSON íŒŒì‹±. ì‹¤íŒ¨ ì‹œ ë¬¸ìì—´ì—ì„œ ë§ˆì§€ë§‰ {} ë¸”ë¡ ì¶”ì¶œ í›„ ì¬ì‹œë„."""
    if not s or not s.strip():
        return None
    try:
        return json.loads(s)
    except Exception:
        m = re.search(r"\{.*\}", s, flags=re.S)
        if not m:
            return None
        try:
            return json.loads(m.group(0))
        except Exception:
            return None


def infer_kpi_labels_with_ai(
    title: str,
    article_text: str,
    numbers: List[Dict[str, Any]],
    publisher: str = "ì„¸ê³„ì¼ë³´",
) -> Optional[List[Dict[str, Any]]]:
    """
    numbers item ì˜ˆì‹œ(ê¶Œì¥):
      {
        "value": 35,
        "unit": "%",
        "raw": "35%",
        "context": "â€¦ì°¬ì„± ë¹„ìœ¨ì€ 35%â€¦",
        "note": "",
        "trend": "neutral"
      }
    """
    client = get_openai_client()
    if not client:
        return None

    text = (article_text or "").strip()
    if len(text) > 6000:
        text = text[:3500] + "\n...\n" + text[-2000:]

    nums = (numbers or [])[:12]

    schema_hint = {
        "kpis": [
            {
                "index": 0,
                "label": "ë¬´ì—‡ì˜ ìˆ˜ì¹˜ì¸ì§€(ì§§ê²Œ)",
                "value": "ì›ë³¸ value ìœ ì§€",
                "unit": "ì›ë³¸ unit ìœ ì§€(ì—†ìœ¼ë©´ ë¹ˆë¬¸ì)",
                "note": "í•„ìš”í•˜ë©´ 10~18ì ì„¤ëª…(ì„ íƒ)",
                "trend": "up|down|neutral (ì„ íƒ, ëª¨ë¥´ë©´ neutral)"
            }
        ]
    }

    system = (
        "ë„ˆëŠ” ì„¸ê³„ì¼ë³´ ì¸í¬ê·¸ë˜í”½ í¸ì§‘ ë°ìŠ¤í¬ë‹¤. "
        "ì…ë ¥: ê¸°ì‚¬ ì œëª©/ë³¸ë¬¸ ì¼ë¶€ + ìˆ«ìë¦¬ìŠ¤íŠ¸(numbers: value/unit/raw/context). "
        "ì¶œë ¥: ê° ìˆ«ìì— ëŒ€í•´ 'ë¼ë²¨(label)'ì„ ë§Œë“ ë‹¤.\n\n"
        "ê·œì¹™:\n"
        "1) ë°˜ë“œì‹œ context(ë¬¸ì¥)ì—ì„œ ì˜ë¯¸ê°€ í™•ì¸ë  ë•Œë§Œ ë¼ë²¨ì„ ì±„ìš´ë‹¤.\n"
        "2) ì˜ë¯¸ê°€ ë¶ˆëª…í™•í•˜ë©´ labelì€ ë¹ˆ ë¬¸ìì—´ë¡œ ë‘ê³  noteì— 'ë¬¸ë§¥ ë¶€ì¡±'ì´ë¼ê³  ì ëŠ”ë‹¤.\n"
        "3) ë¼ë²¨ì€ 6~10ì ë‚´ì˜ ì§§ì€ ëª…ì‚¬êµ¬(ì˜ˆ: 'ì°¬ì„± ë¹„ìœ¨', 'ì‘ë‹µì ìˆ˜', 'í”¼í•´ì ìˆ˜').\n"
        "4) ì ˆëŒ€ ê¸°ì‚¬ì— ì—†ëŠ” ë‹¨ì–´/ìˆ˜ì¹˜ë¥¼ ë§Œë“¤ì–´ë‚´ì§€ ì•ŠëŠ”ë‹¤.\n"
        "5) trendëŠ” â–²/â–¼/ì¦ê°€/ê°ì†Œ/ìƒìŠ¹/í•˜ë½ì´ context/rawì— ìˆì„ ë•Œë§Œ up/down, ì•„ë‹ˆë©´ neutral.\n"
    )

    user = {
        "publisher": publisher,
        "title": title,
        "article_excerpt": text,
        "numbers": nums,
        "output_schema": schema_hint
    }

    try:
        resp = client.chat.completions.create(
            model="gpt-4o-mini",
            temperature=0.2,
            messages=[
                {"role": "system", "content": system},
                {"role": "user", "content": json.dumps(user, ensure_ascii=False)},
            ],
            response_format={"type": "json_object"},
        )
        content = resp.choices[0].message.content
        data = _safe_json_loads(content or "")
        if not data or "kpis" not in data:
            return None

        kpis = data["kpis"]
        if not isinstance(kpis, list):
            return None

        merged = []
        for i, n in enumerate(nums):
            out = next((x for x in kpis if isinstance(x, dict) and x.get("index") == i), None)
            label = (out.get("label") if out else "") or ""
            note = (out.get("note") if out else "") or n.get("note", "") or ""
            trend_src = (n.get("raw", "") + " " + n.get("context", "")).strip()
            trend = (out.get("trend") if out else "") or classify_trend(trend_src)
            trend = trend if trend in ("up", "down", "neutral") else "neutral"

            merged.append({
                **n,
                "label": label.strip(),
                "note": note.strip(),
                "trend": trend,
            })

        return merged

    except Exception as e:
        st.warning(f"AI ë¼ë²¨ ìƒì„± ì‹¤íŒ¨: {e}")
        return None


def enrich_labels(title: str, summary: str, text: str, numbers: list[dict]) -> dict:
    """ìˆ«ì ëª©ë¡ì— ëŒ€í•´ label ìƒì„± í›„ JSON ë°˜í™˜. ì‹¤íŒ¨ ì‹œ ë¹ˆ dict."""
    client = get_openai_client()
    if not client:
        return {}

    prompt = f"""
ê¸°ì‚¬ ì œëª©:
{title}

ê¸°ì‚¬ ìš”ì•½:
{summary}

ë³¸ë¬¸ ì¼ë¶€:
{(text or "")[:2000]}

ìˆ«ì ëª©ë¡:
{json.dumps(numbers, ensure_ascii=False)}

ê° ìˆ«ìì— ëŒ€í•´ label(6ë‹¨ì–´ ì´í•˜ KPI ë¼ë²¨), value(ìˆ«ìë§Œ), unit(ë‹¨ìœ„), note(ë§¥ë½ í•œ ì¤„), drop(ë¶ˆëª…í™• ì‹œ true)ë¥¼ ì±„ì›Œ JSON ë°˜í™˜.
í˜•ì‹: {"items": [{"label":"", "value":"", "unit":"", "note":"", "drop": false ë˜ëŠ” true}, ...]} ìˆœì„œëŠ” ìˆ«ì ëª©ë¡ê³¼ ë™ì¼í•˜ê²Œ.
"""

    try:
        res = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": "ë‰´ìŠ¤ ë°ì´í„° ë¼ë²¨ ìƒì„±ê¸°"},
                {"role": "user", "content": prompt},
            ],
            temperature=0.2,
            response_format={"type": "json_object"},
        )
        raw = res.choices[0].message.content or "{}"
        return json.loads(raw)
    except Exception:
        return {}


def refine_numbers_with_openai(
    numbers: list[dict],
    title_hint: str = "",
    summary: str = "",
    text: str = "",
) -> list[dict]:
    """
    input: [{"label": "...", "value": "3.5%", "context": "..."}...]
    output: [{"label": "ê¸°ì¤€ê¸ˆë¦¬", "value": "3.50", "unit": "%", "note": "â€¦"} ...]
    text/summary ìˆìœ¼ë©´ enrich_labelsë¡œ ë¨¼ì € ë¼ë²¨ ìƒì„± í›„ ì‚¬ìš©.
    """
    client = get_openai_client()
    if client is None:
        return numbers

    if not numbers:
        return []

    nums_in = numbers[:8]
    title = title_hint or ""
    article_text = (text or "").strip()
    article_summary = (summary or "").strip()

    if article_text or article_summary:
        enriched = enrich_labels(title, article_summary, article_text, nums_in)
        items = enriched.get("items") or []
        for i, n in enumerate(nums_in):
            if i < len(items) and items[i].get("label"):
                n["label"] = (items[i].get("label") or "").strip()

    system = (
        "ë„ˆëŠ” ê²½ì œÂ·ì •ì±…Â·ì‚¬íšŒ ë‰´ìŠ¤ë¥¼ í•´ì„í•˜ëŠ” ë°ì´í„° ì—ë””í„°ë‹¤. "
        "ì£¼ì–´ì§„ ìˆ«ì ë¦¬ìŠ¤íŠ¸ë¥¼ ë³´ê³ , ê¸°ì‚¬ ë§¥ë½ì— ë§ëŠ” 'ì§§ê³  ëª…í™•í•œ KPI ë¼ë²¨'ì„ ìƒì„±í•˜ë¼. "
        "ê·œì¹™: 6ë‹¨ì–´ ì´í•˜, ë‰´ìŠ¤ ê·¸ë˜í”½ ìŠ¤íƒ€ì¼, êµ¬ì²´ì  ì˜ë¯¸ ë°˜ì˜, ëª¨í˜¸í•œ í‘œí˜„ ê¸ˆì§€, "
        "ë‹¨ìˆœ 'ìˆ˜ì¹˜'Â·'ë°ì´í„°' ê¸ˆì§€, ê°€ëŠ¥í•œ ê²½ìš° ë‹¨ìœ„ ì˜ë¯¸ í¬í•¨. "
        "ê¸°ì‚¬ì— ê·¼ê±° ì—†ëŠ” í•´ì„/ì¶”ì¸¡ì€ í•˜ì§€ ì•ŠëŠ”ë‹¤."
    )

    summary_for_prompt = article_summary or ""
    text_excerpt = (
        article_text[:2000]
        if article_text
        else "\n".join(
            (i.get("context") or "").strip() for i in nums_in if (i.get("context") or "").strip()
        )[:2000] or "(ì—†ìŒ)"
    )
    numbers_json = json.dumps(nums_in, ensure_ascii=False, indent=0)

    user_content = f"""ê¸°ì‚¬ ì œëª©:
{title}

ê¸°ì‚¬ ìš”ì•½:
{summary_for_prompt}

ë³¸ë¬¸ ì¼ë¶€:
{text_excerpt}

ìˆ«ì ëª©ë¡:
{numbers_json}

ê° ìˆ«ìì— ëŒ€í•´ label í•„ë“œë¥¼ ìƒì„±í•´ JSONìœ¼ë¡œ ë°˜í™˜í•˜ë¼.
ê° itemì— ëŒ€í•´ label(6ë‹¨ì–´ ì´í•˜ KPI ë¼ë²¨), value(ìˆ«ìë§Œ), unit(ë‹¨ìœ„), note(ë§¥ë½ í•œ ì¤„), drop(ë¶ˆëª…í™• ì‹œ true)ë¥¼ ì±„ì›Œë¼.
ì¶œë ¥ í˜•ì‹: {{"items": [{{"label":"", "value":"", "unit":"", "note":"", "drop": false ë˜ëŠ” true}}, ...]}} ìˆœì„œëŠ” ìˆ«ì ëª©ë¡ê³¼ ë™ì¼í•˜ê²Œ."""

    try:
        resp = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": system},
                {"role": "user", "content": user_content},
            ],
            temperature=0.2,
            response_format={"type": "json_object"},
        )
        raw = resp.choices[0].message.content or ""
        data = json.loads(raw)
    except Exception:
        return numbers

    out = []
    for it in data.get("items", []):
        if it.get("drop") is True:
            continue
        out.append({
            "label": (it.get("label") or "").strip(),
            "value": (it.get("value") or "").strip(),
            "unit": (it.get("unit") or "").strip(),
            "note": (it.get("note") or "").strip(),
        })

    return out[:6]


def analyze_for_desk(article_text: str, title_hint: str = "", url: str = "") -> dict:
    client = get_openai_client()
    if client is None:
        raise RuntimeError("OPENAI_API_KEY not set")

    article_text = (article_text or "").strip()
    if not article_text:
        raise ValueError("empty article_text")

    if len(article_text) > 12000:
        article_text = article_text[:12000] + "\n...(ìƒëµ)..."

    system = (
        "ë„ˆëŠ” ì‹ ë¬¸ì‚¬ í¸ì§‘ ë°ìŠ¤í¬ì˜ AI ë³´ì¡°ë‹¤. "
        "ê¸°ì‚¬ ë³¸ë¬¸ë§Œì„ ê·¼ê±°ë¡œ í¸ì§‘/ê²€ì¦ ê´€ì ì˜ ë¦¬í¬íŠ¸ë¥¼ ë§Œë“ ë‹¤. "
        "ì¶”ì¸¡ ê¸ˆì§€, ì‚¬ì‹¤ ë‹¨ì • ê¸ˆì§€. ê¸°ì‚¬ì— ì—†ëŠ” ì •ë³´ëŠ” 'ì•Œ ìˆ˜ ì—†ìŒ'ìœ¼ë¡œ í‘œì‹œ."
    )

    prompt = {
        "task": "desk_analysis",
        "inputs": {"url": url, "title_hint": title_hint, "article_text": article_text},
        "output_spec": {
            "summary_1": "í•œ ë¬¸ì¥ ìš”ì•½(30~60ì)",
            "angle": "ê¸°ì‚¬ì˜ ê´€ì /í”„ë ˆì´ë°(ê°„ë‹¨)",
            "key_facts": ["íŒ©íŠ¸ 5ê°œ(ê° 20~60ì)"],
            "numbers_check": [
                {"claim": "ìˆ˜ì¹˜ ì£¼ì¥", "value": "ìˆ«ì", "unit": "ë‹¨ìœ„", "needs_verify": "True/False", "why": "ì´ìœ "}
            ],
            "sensitivity": {
                "level": "low|medium|high",
                "reasons": ["ë¯¼ê° ìš”ì†Œ"],
                "suggestions": ["í†¤ ì¡°ì •/í‘œí˜„ ì™„í™” ì œì•ˆ"]
            },
            "legal_copyright": {"risk": "low|medium|high", "notes": ["ì¸ìš©/ì´ë¯¸ì§€ ì£¼ì˜"]},
            "headlines": ["ëŒ€ì²´ í—¤ë“œë¼ì¸ 3ê°œ"],
            "seo_keywords": ["í‚¤ì›Œë“œ 8ê°œ"],
            "followups": ["ì¶”ê°€ ì·¨ì¬/í™•ì¸ ì§ˆë¬¸ 5ê°œ"]
        }
    }

    try:
        resp = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": system},
                {"role": "user", "content": json.dumps(prompt, ensure_ascii=False)},
            ],
            temperature=0.2,
            response_format={"type": "json_object"},
        )
        raw = resp.choices[0].message.content or ""
        return json.loads(raw)
    except Exception as e:
        raise RuntimeError(f"desk analysis failed: {e}") from e


from jinja2 import Environment, FileSystemLoader, select_autoescape
from extractor import extract_article, has_numbers, extract_numbers_with_context, choose_kpis

DESK_KEY = "ì›í•˜ëŠ”_ê¸´_ë¹„ë°€ë²ˆí˜¸"


def is_desk_mode() -> bool:
    qp = st.query_params
    return qp.get("mode", "") == "desk"


def desk_auth_ok() -> bool:
    if st.session_state.get("desk_authed"):
        return True

    key = None
    try:
        key = st.secrets.get("DESK_KEY")
    except Exception:
        key = None
    if not key:
        return False

    with st.sidebar:
        st.markdown("### ë°ìŠ¤í¬ ëª¨ë“œ")
        pw = st.text_input("DESK KEY", type="password")
        if st.button("Unlock"):
            if pw == key:
                st.session_state["desk_authed"] = True
                st.success("Unlocked")
                return True
            st.error("Wrong key")
    return False


def normalize_url(u: str) -> str:
    u = (u or "").strip()
    if not u:
        return ""
    # ì‚¬ìš©ìê°€ www ì—†ì´ ì…ë ¥í•´ë„ ë³´ì •
    if u.startswith("www."):
        u = "https://" + u
    return u


def is_allowed_url(u: str) -> bool:
    try:
        host = urlparse(u).netloc.lower()
        # segye.com í•˜ìœ„ ë„ë©”ì¸ í¬í•¨ í—ˆìš© (www.segye.com ë“±)
        return host.endswith("segye.com")
    except Exception:
        return False


def guard_rate_limit(seconds: int = 8):
    now = time.time()
    if now - st.session_state.last_fetch_ts < seconds:
        st.warning(f"ìš”ì²­ì´ ë„ˆë¬´ ë¹ ë¦…ë‹ˆë‹¤. {seconds}ì´ˆ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")
        st.stop()
    st.session_state.last_fetch_ts = now


_SENT_SPLIT = re.compile(r"(?<=[.!?ã€‚â€¦])\s+|\n+")


def make_simple_keypoints(text: str, k: int = 3) -> list[str]:
    text = (text or "").strip()
    if not text:
        return ["", "", ""]
    sents = [s.strip() for s in _SENT_SPLIT.split(text) if len(s.strip()) >= 25]
    picked = sents[:k]
    picked = (picked + ["", "", ""])[:3]
    return picked


def classify_trend(value_any) -> str:
    """
    value_any: str | int | float | None
    ë°˜í™˜: "up" | "down" | "neutral"
    ê·œì¹™:
      - í…ìŠ¤íŠ¸ì— 'ì¦ê°€/ìƒìŠ¹/ëŠ˜' ë˜ëŠ” â–² / + í¬í•¨ â†’ up
      - í…ìŠ¤íŠ¸ì— 'ê°ì†Œ/í•˜ë½/ì¤„' ë˜ëŠ” â–¼ / - í¬í•¨ â†’ down
      - ìˆ«ìë§Œ ìˆìœ¼ë©´ ë°©í–¥ íŒë‹¨ ë¶ˆê°€ â†’ neutral
    """
    if value_any is None:
        return "neutral"

    # ìˆ«ìë©´ ë°©í–¥ íŒë‹¨ ë¶ˆê°€(ë¬¸ë§¥ì´ ì—†ìœ¼ë‹ˆ)
    if isinstance(value_any, (int, float)):
        return "neutral"

    # ê·¸ ì™¸ëŠ” ë¬¸ìì—´ë¡œ ì²˜ë¦¬
    s = str(value_any).strip()

    # ê¸°í˜¸ ê¸°ë°˜
    if "â–²" in s or "ìƒìŠ¹" in s or "ì¦ê°€" in s or "ëŠ˜" in s or re.search(r"\+\s*\d", s):
        return "up"
    if "â–¼" in s or "í•˜ë½" in s or "ê°ì†Œ" in s or "ì¤„" in s or re.search(r"-\s*\d", s):
        return "down"

    return "neutral"


def make_simple_callout(text: str, max_len: int = 160) -> str:
    text = (text or "").strip()
    if not text:
        return ""
    t = text.replace("\n", " ")
    return (t[:max_len] + "â€¦") if len(t) > max_len else t


def wrap_headline(text: str, width: int = 18) -> list[str]:
    words = (text or "").strip().split()
    lines = []
    current = ""

    for w in words:
        if len(current + w) < width:
            current += w + " "
        else:
            lines.append(current.strip())
            current = w + " "

    if current.strip():
        lines.append(current.strip())
    return lines[:2]


# (ì„ íƒ) SVG -> PNG ë³€í™˜
# pip install cairosvg
# import cairosvg

st.set_page_config(page_title="SEGYE.ON Infographic", layout="wide")

# -----------------------------
# Jinja2 í™˜ê²½
# -----------------------------
env = Environment(
    loader=FileSystemLoader("templates"),
    autoescape=select_autoescape(enabled_extensions=("svg", "j2", "xml")),
)
_tpl = {
    "story_lite": env.get_template("story_lite.svg.j2"),
    "data_focus": env.get_template("data_focus.svg.j2"),
    "timeline": env.get_template("timeline.svg.j2"),
    "compare": env.get_template("compare.svg.j2"),
}


def _load_font_base64():
    """regular.txt, bold.txtê°€ ìˆìœ¼ë©´ base64 ë¬¸ìì—´ ë°˜í™˜ (SVG data URI ì„ë² ë“œìš©)."""
    base_dir = os.path.dirname(os.path.abspath(__file__))
    out = {}
    for key, filename in (("font_regular_b64", "regular.txt"), ("font_bold_b64", "bold.txt")):
        path = os.path.join(base_dir, filename)
        if os.path.isfile(path):
            try:
                with open(path, "r", encoding="ascii") as f:
                    out[key] = f.read().strip()
            except Exception:
                pass
    return out


def render_svg(template_key: str, render_model: dict) -> str:
    tpl = _tpl.get(template_key) or _tpl["story_lite"]
    chart = render_model.get("chart") if isinstance(render_model, dict) else None
    rm = {**render_model, "chart": chart}
    rm.update(_load_font_base64())
    return tpl.render(**rm)

def default_spec():
    return {
        "meta": {"source_url":"", "title":"", "publisher":"ì„¸ê³„ì¼ë³´", "date":"", "byline":"", "language":"ko"},
        "style": {"brand":"segye", "tone":"clean_serif_like", "density":"low", "output":["svg","png"]},
        "content": {
            "headline":"", "dek":"", "keywords":[],
            "key_points":[
                {"text":"", "evidence":"", "confidence":0.0},
                {"text":"", "evidence":"", "confidence":0.0},
                {"text":"", "evidence":"", "confidence":0.0}
            ],
            "quote":{"speaker":"", "org":"", "text":""},
            "numbers":[],
            "numbers_all":[],
            "charts":[],
            "timeline":[],
            "comparison":{"left_title":"", "right_title":"", "items":[]},
            "callouts":[{"title":"í•µì‹¬ ë§¥ë½", "body":""}],
            "sources":[]
        },
        "layout":{"template":"story_lite", "ratio":"1:1", "sections":["headline","key_points","callout","sources"]}
    }

def choose_layout(spec: dict) -> dict:
    c = spec.get("content", {})
    if len(c.get("charts", [])) >= 1 or len(c.get("numbers", [])) >= 2:
        return {"template":"data_focus", "ratio":"1:1", "sections":["headline","chart","key_points","sources"]}
    if len(c.get("timeline", [])) >= 4:
        return {"template":"timeline", "ratio":"1:1", "sections":["headline","timeline","key_points","sources"]}
    comp_items = c.get("comparison", {}).get("items", [])
    if len(comp_items) >= 3:
        return {"template":"compare", "ratio":"1:1", "sections":["headline","comparison","key_points","sources"]}
    return {"template":"story_lite", "ratio":"1:1", "sections":["headline","key_points","callout","sources"]}

def build_render_model(spec: dict) -> dict:
    meta = spec["meta"]
    c = spec["content"]

    kp = [xml_escape(x.get("text", "")) for x in c.get("key_points", [])]
    kp = (kp + ["", "", ""])[:3]

    quote = c.get("quote", {})
    quote_line = xml_escape(quote.get("text", "").strip())

    callout = (c.get("callouts", [{}]) + [{}])[0]
    callout_title = xml_escape(callout.get("title", "").strip())
    callout_body = xml_escape(callout.get("body", "").strip())

    url = meta.get("source_url", "").strip()
    url_short = url.replace("https://", "").replace("http://", "")
    if len(url_short) > 42:
        url_short = url_short[:39] + "..."
    sources_line = xml_escape(f"ì¶œì²˜: {meta.get('publisher','')} Â· {meta.get('date','')} Â· {url_short}".strip())

    # data_focus
    charts = c.get("charts", [])
    chart_title = xml_escape(charts[0].get("title", "").strip() if charts else "")
    chart_note = xml_escape(charts[0].get("note", "").strip() if charts else "")
    nums = c.get("numbers", [])[:4]
    for n in nums:
        if not n.get("label"):
            n["label"] = "í•µì‹¬ ì§€í‘œ"
        n["trend"] = classify_trend(n.get("raw") or n.get("context") or "")
    numbers = nums[:2]
    big1 = xml_escape(str(numbers[0].get("value", "")) if numbers else "")
    big1_label = xml_escape((numbers[0].get("label", "") or numbers[0].get("context", "") or "").strip() if numbers else "")
    big2 = xml_escape(str(numbers[1].get("value", "")) if len(numbers) > 1 else "")
    big2_label = xml_escape((numbers[1].get("label", "") or numbers[1].get("context", "") or "").strip() if len(numbers) > 1 else "")
    if c.get("chart"):
        if c["chart"].get("title"):
            chart_title = xml_escape(c["chart"].get("title", ""))
        if c["chart"].get("note"):
            chart_note = xml_escape(c["chart"].get("note", ""))

    # timeline
    tl = c.get("timeline", [])[:8]
    text_timeline = [{"date": xml_escape(t.get("date", "")), "event": xml_escape(t.get("event", ""))} for t in tl]

    # compare
    comp = c.get("comparison", {}) or {}
    comp_items = (comp.get("items") or [])[:6]
    compare_rows = [{"left": xml_escape(i.get("left", "")), "right": xml_escape(i.get("right", ""))} for i in comp_items]

    # --- Chart data preparation ---
    chart_items = []
    values = []

    for n in nums:
        raw = str(n.get("value", "")).replace(",", "").strip()
        try:
            val = float(raw)
        except Exception:
            continue
        label = xml_escape((n.get("label") or "").strip())
        values.append(val)
        chart_items.append({"label": label, "value": val})

    chart_max = max(values) if values else 0.0
    for item in chart_items:
        item["norm"] = (item["value"] / chart_max) if chart_max > 0 else 0.0

    chart_type = "donut" if len(chart_items) == 2 else "bar"
    chart_obj = {"items": chart_items, "max": chart_max, "type": chart_type}

    headline = c.get("headline", "").strip()
    headline_lines = [xml_escape(line) for line in wrap_headline(headline)]

    # numbers: SVGì— ë„£ì„ ë³µì‚¬ë³¸ì— escape ì ìš© (ì›ë³¸ specì€ ë³€ê²½í•˜ì§€ ì•ŠìŒ)
    numbers_escaped = [
        {
            "label": xml_escape(n.get("label", "")),
            "value": xml_escape(str(n.get("value", ""))),
            "unit": xml_escape(n.get("unit", "")),
            "note": xml_escape(n.get("note", "")),
            "trend": n.get("trend", "neutral"),
        }
        for n in nums
    ]

    return {
        "canvas": {"w": 1080, "h": 1080, "margin": 72},
        "text": {
            "headline": xml_escape(headline),
            "headline_lines": headline_lines,
            "dek": xml_escape(c.get("dek", "").strip()),
            "keywords": [xml_escape(k) for k in c.get("keywords", [])[:6]],
            "key_points": kp,
            "quote_line": quote_line,
            "callout_title": callout_title,
            "callout_body": callout_body,
            "sources_line": sources_line,
            "chart_title": chart_title,
            "chart_note": chart_note,
            "big1": big1,
            "big1_label": big1_label,
            "big2": big2,
            "big2_label": big2_label,
            "timeline": text_timeline,
            "left_title": xml_escape(comp.get("left_title", "")),
            "right_title": xml_escape(comp.get("right_title", "")),
            "compare_rows": compare_rows,
        },
        "flags": {
            "has_quote": bool(quote_line),
            "has_callout": bool(callout_title or callout_body)
        },
        "numbers": c.get("numbers", []),
        "chart": (c.get("charts") or [None])[0],
    }

# -----------------------------
# Session state
# -----------------------------
if "spec" not in st.session_state:
    st.session_state.spec = default_spec()
if "dirty" not in st.session_state:
    st.session_state.dirty = False
if "svg" not in st.session_state:
    st.session_state.svg = ""
if "last_fetch_ts" not in st.session_state:
    st.session_state.last_fetch_ts = 0.0


def generate_draft_with_openai(article_text: str, title_hint: str = "") -> dict:
    """ê¸°ì‚¬ ë³¸ë¬¸ìœ¼ë¡œ headline, dek, key_points(3), callout, quote ì´ˆì•ˆ ìƒì„±. ì‹¤íŒ¨ ì‹œ ê·œì¹™ ê¸°ë°˜ fallback."""
    kp = make_simple_keypoints(article_text, k=3)
    fallback = {
        "headline": (title_hint or "").strip(),
        "dek": "",
        "key_points": kp,
        "callout_title": "í•µì‹¬ ë§¥ë½",
        "callout_body": make_simple_callout(article_text),
        "quote_text": "",
    }
    client = get_openai_client()
    if not client:
        return fallback
    prompt = f"""ë‹¤ìŒ ê¸°ì‚¬ ë‚´ìš©ì„ ì¸í¬ê·¸ë˜í”½ ì´ˆì•ˆìœ¼ë¡œ ìš”ì•½í•˜ì„¸ìš”. ë°˜ë“œì‹œ JSONë§Œ ì¶œë ¥.
í˜•ì‹: {{"headline":"","dek":"","key_points":["","",""],"callout_title":"","callout_body":"","quote_text":""}}

key_points ì‘ì„± ê¸°ì¤€: ê¸°ì‚¬ì—ì„œ ë…ìê°€ ì•Œì•„ì•¼ í•  í•µì‹¬ ì¸ì‚¬ì´íŠ¸ 3ê°œ ì‘ì„±. ìˆ«ìì™€ ì˜ë¯¸ í¬í•¨, ì§§ê³  ê°•í•˜ê²Œ, ë‰´ìŠ¤ í†¤ ìœ ì§€.

ê¸°ì‚¬:
{(article_text or "")[:6000]}
"""
    try:
        resp = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.3,
            response_format={"type": "json_object"},
        )
        raw = resp.choices[0].message.content or "{}"
        data = json.loads(raw)
        return {
            "headline": (data.get("headline") or fallback["headline"]).strip(),
            "dek": (data.get("dek") or "").strip(),
            "key_points": [(data.get("key_points") or [])[i] if i < len(data.get("key_points") or []) else fallback["key_points"][i] for i in range(3)],
            "callout_title": (data.get("callout_title") or fallback["callout_title"]).strip(),
            "callout_body": (data.get("callout_body") or fallback["callout_body"]).strip(),
            "quote_text": (data.get("quote_text") or "").strip(),
        }
    except Exception:
        return fallback


def run_desk_mode():
    st.title("SEGYE.ON â€” AI í¸ì§‘ ë°ìŠ¤í¬")
    st.caption("ì„¸ê³„ì¼ë³´ ê¸°ì‚¬ ê¸°ë°˜ ìë™ ë¶„ì„/ê²€ì¦/ì¸í¬ê·¸ë˜í”½ ìƒì„± ì½˜ì†”")

    left, right = st.columns([0.42, 0.58], gap="large")

    with left:
        st.subheader("ì…ë ¥")
        url = st.text_input("ì„¸ê³„ì¼ë³´ URL (segye.com)", value=st.session_state.spec["meta"].get("source_url", ""))
        url = normalize_url(url)

        c1, c2, c3 = st.columns(3)
        do_fetch = c1.button("URL ë¶ˆëŸ¬ì˜¤ê¸°", use_container_width=True)
        do_draft = c2.button("AI ì´ˆì•ˆ", use_container_width=True)
        do_analyze = c3.button("ë°ìŠ¤í¬ ë¶„ì„", use_container_width=True)

        if do_fetch:
            if not url or not is_allowed_url(url):
                st.error("ì„¸ê³„ì¼ë³´(segye.com) URLë§Œ ì§€ì›í•©ë‹ˆë‹¤.")
                st.stop()
            guard_rate_limit(6)
            data = extract_article(url)

            st.session_state.spec["meta"]["source_url"] = data.url
            st.session_state.spec["meta"]["title"] = data.title
            st.session_state.spec["meta"]["date"] = data.published
            st.session_state.spec["meta"]["byline"] = data.byline

            st.session_state["article_text"] = data.content
            st.session_state["og_image"] = data.og_image

            if not st.session_state.spec["content"]["headline"]:
                st.session_state.spec["content"]["headline"] = (data.title or "").strip()

            nums = extract_numbers_with_context(data.content, max_items=20)
            st.session_state.spec["content"]["numbers_all"] = nums or []
            st.session_state.spec["content"]["numbers"] = choose_kpis(nums or [], k=4)
            st.session_state["template_hint"] = "data_focus" if len(st.session_state.spec["content"]["numbers"]) >= 2 else "story_lite"

            st.success("ê¸°ì‚¬ ë¡œë“œ ì™„ë£Œ")

        if do_draft:
            article_text = st.session_state.get("article_text", "")
            if not article_text:
                st.warning("ë¨¼ì € URL ë¶ˆëŸ¬ì˜¤ê¸°ë¥¼ í•˜ì„¸ìš”.")
                st.stop()

            draft = generate_draft_with_openai(article_text, st.session_state.spec["meta"].get("title", ""))
            st.session_state.spec["content"]["headline"] = draft["headline"] or st.session_state.spec["content"]["headline"]
            st.session_state.spec["content"]["dek"] = draft.get("dek", "")
            st.session_state.spec["content"]["key_points"][0]["text"] = draft["key_points"][0]
            st.session_state.spec["content"]["key_points"][1]["text"] = draft["key_points"][1]
            st.session_state.spec["content"]["key_points"][2]["text"] = draft["key_points"][2]
            st.session_state.spec["content"]["callouts"][0]["title"] = draft.get("callout_title", "í•µì‹¬ ë§¥ë½")
            st.session_state.spec["content"]["callouts"][0]["body"] = draft.get("callout_body", "")
            st.session_state.spec["content"]["quote"]["text"] = draft.get("quote_text", "")

            nums_raw = extract_numbers_with_context(article_text, max_items=10)
            nums_refined = refine_numbers_with_openai(
                nums_raw,
                title_hint=st.session_state.spec["meta"].get("title", ""),
                text=st.session_state.get("article_text", ""),
            )
            st.session_state.spec["content"]["numbers"] = nums_refined
            st.session_state["template_hint"] = "data_focus" if len(nums_refined) >= 2 else "story_lite"
            st.success("AI ì´ˆì•ˆ ìƒì„± ì™„ë£Œ")

        if do_analyze:
            article_text = st.session_state.get("article_text", "")
            if not article_text:
                st.warning("ë¨¼ì € URL ë¶ˆëŸ¬ì˜¤ê¸°ë¥¼ í•˜ì„¸ìš”.")
                st.stop()

            with st.spinner("ë°ìŠ¤í¬ ë¶„ì„ ì¤‘..."):
                report = analyze_for_desk(
                    article_text=article_text,
                    title_hint=st.session_state.spec["meta"].get("title", ""),
                    url=st.session_state.spec["meta"].get("source_url", "")
                )
                st.session_state["desk_report"] = report
            st.success("ë°ìŠ¤í¬ ë¦¬í¬íŠ¸ ìƒì„± ì™„ë£Œ")

        do_label = st.button("ğŸ§  ë¼ë²¨ ìë™ ìƒì„±", use_container_width=True)
        if do_label:
            article_text = st.session_state.get("article_text", "")
            numbers = list(st.session_state.spec["content"].get("numbers", []))
            if not article_text:
                st.warning("ë¨¼ì € URL ë¶ˆëŸ¬ì˜¤ê¸°ë¥¼ í•˜ì„¸ìš”.")
                st.stop()
            if not numbers:
                st.warning("ë¨¼ì € AI ì´ˆì•ˆì„ ì‹¤í–‰í•´ ìˆ«ìë¥¼ ì¶”ì¶œí•˜ì„¸ìš”.")
                st.stop()
            with st.spinner("ë¼ë²¨ ìƒì„± ì¤‘..."):
                enriched = enrich_labels(
                    st.session_state.spec["meta"].get("title", ""),
                    "",
                    article_text,
                    numbers,
                )
            items = enriched.get("items") or []
            for i, n in enumerate(numbers):
                if i < len(items) and items[i].get("label"):
                    n["label"] = (items[i].get("label") or "").strip()
            st.session_state.spec["content"]["numbers"] = numbers
            st.success("ë¼ë²¨ ì ìš© ì™„ë£Œ")

        st.divider()
        st.subheader("KPI ë¼ë²¨ ìë™ ìƒì„±(AI)")
        if st.button("AIë¡œ KPI ë¼ë²¨ ì±„ìš°ê¸°", use_container_width=True, key="kpi_label_desk"):
            numbers = st.session_state.spec["content"].get("numbers", [])
            if not numbers:
                st.info("ì¶”ì¶œëœ ìˆ˜ì¹˜ê°€ ì—†ìŠµë‹ˆë‹¤. (ë³¸ë¬¸ì— ìˆ«ìê°€ ì—†ê±°ë‚˜ ì¶”ì¶œ ê·œì¹™ì— ì•ˆ ì¡í˜”ì–´ìš”)")
            else:
                title = st.session_state.spec["meta"].get("title", "") or st.session_state.spec["content"].get("headline", "")
                article_text = st.session_state.get("article_text", "") or ""
                labeled = infer_kpi_labels_with_ai(
                    title=title,
                    article_text=article_text,
                    numbers=numbers,
                    publisher=st.session_state.spec["meta"].get("publisher", "ì„¸ê³„ì¼ë³´")
                )
                if labeled:
                    st.session_state.spec["content"]["numbers"] = labeled
                    st.success("KPI ë¼ë²¨ì„ ì±„ì› ìŠµë‹ˆë‹¤. (í•„ìš”í•˜ë©´ ì¼ë¶€ë§Œ ìˆ˜ì • í›„ ë Œë”í•˜ì„¸ìš”.)")
                    st.session_state.dirty = True
                else:
                    st.info("AI ë¼ë²¨ ìƒì„± ê²°ê³¼ê°€ ì—†ê±°ë‚˜ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. (API í‚¤/ë³¸ë¬¸/ìˆ«ì ì¶”ì¶œì„ í™•ì¸)")

        st.divider()

        report = st.session_state.get("desk_report")
        if report:
            st.subheader("ë°ìŠ¤í¬ ë¦¬í¬íŠ¸")
            st.write("**ìš”ì•½**:", report.get("summary_1", ""))
            st.write("**ê´€ì /í”„ë ˆì´ë°**:", report.get("angle", ""))

            with st.expander("íŒ©íŠ¸ 5ê°œ", expanded=True):
                for x in report.get("key_facts", [])[:5]:
                    st.write("â€¢", x)

            with st.expander("ìˆ˜ì¹˜ ê²€ì¦ ì²´í¬", expanded=True):
                for it in report.get("numbers_check", [])[:8]:
                    st.write(f"- {it.get('claim', '')}")
                    st.caption(f"ê°’: {it.get('value', '')} {it.get('unit', '')} / ê²€ì¦í•„ìš”: {it.get('needs_verify')} / ì´ìœ : {it.get('why', '')}")

            with st.expander("ë¯¼ê°ë„/ë¦¬ìŠ¤í¬", expanded=True):
                s = report.get("sensitivity", {})
                st.write("**Level**:", s.get("level", ""))
                for r in s.get("reasons", [])[:6]:
                    st.write("â€¢", r)
                for sug in s.get("suggestions", [])[:6]:
                    st.write("âœ…", sug)

            with st.expander("í—¤ë“œë¼ì¸ ì œì•ˆ / í‚¤ì›Œë“œ", expanded=False):
                for h in report.get("headlines", [])[:3]:
                    st.write("â€¢", h)
                st.write("í‚¤ì›Œë“œ:", ", ".join(report.get("seo_keywords", [])[:8]))

            with st.expander("í›„ì† ì§ˆë¬¸(ì¶”ê°€ ì·¨ì¬/í™•ì¸)", expanded=False):
                for q in report.get("followups", [])[:6]:
                    st.write("â€¢", q)

        with st.expander("í¸ì§‘(ì„ íƒ) â€” í—¤ë“œë¼ì¸/í‚¤í¬ì¸íŠ¸ ìˆ˜ì •", expanded=False):
            st.session_state.spec["content"]["headline"] = st.text_input("í—¤ë“œë¼ì¸", value=st.session_state.spec["content"]["headline"])
            st.session_state.spec["content"]["dek"] = st.text_input("ì„œë¸Œ", value=st.session_state.spec["content"]["dek"])
            for i in range(3):
                st.session_state.spec["content"]["key_points"][i]["text"] = st.text_area(
                    f"í‚¤í¬ì¸íŠ¸ {i+1}",
                    value=st.session_state.spec["content"]["key_points"][i]["text"],
                    height=70
                )

            _opts = ["story_lite", "data_focus", "timeline", "compare"]
            default_tpl = st.session_state.get("template_hint", "story_lite")
            template = st.radio("í…œí”Œë¦¿", options=_opts, index=_opts.index(default_tpl) if default_tpl in _opts else 0, horizontal=True)
            st.session_state["template"] = template

            if st.button("ìƒì„±(ë Œë”)", use_container_width=True):
                st.session_state.spec["layout"] = choose_layout(st.session_state.spec)
                rm = build_render_model(st.session_state.spec)
                tpl_key = st.session_state.get("template") or st.session_state.get("template_hint") or "story_lite"
                st.session_state.svg = render_svg(tpl_key, rm)

    with right:
        st.subheader("ë¯¸ë¦¬ë³´ê¸°(ê³ ì •)")
        if st.session_state.svg:
            st.components.v1.html(st.session_state.svg, height=1120, scrolling=True)

            st.download_button("SVG ë‹¤ìš´ë¡œë“œ", st.session_state.svg.encode("utf-8"), "segye_infographic.svg", "image/svg+xml")

            try:
                import cairosvg
                safe_svg = sanitize_svg_for_png(st.session_state.svg)
                safe_svg = strip_css_import(safe_svg)
                safe_svg = svg_fonts_to_absolute_paths(safe_svg)
                png_bytes = cairosvg.svg2png(bytestring=safe_svg.encode("utf-8"))
                st.download_button(
                    label="PNG ë‹¤ìš´ë¡œë“œ",
                    data=png_bytes,
                    file_name="segye_infographic.png",
                    mime="image/png"
                )
            except Exception as e:
                st.warning(f"PNG ë³€í™˜ ì‹¤íŒ¨: {e}")
                lines = (st.session_state.svg or "").splitlines()
                if len(lines) >= 6:
                    st.caption("ë””ë²„ê·¸: SVG ìƒë‹¨ 8ì¤„")
                    st.code("\n".join(lines[:8]))
        else:
            st.info("ì¢Œì¸¡ì—ì„œ URL ë¶ˆëŸ¬ì˜¤ê¸° â†’ AI ì´ˆì•ˆ/ë°ìŠ¤í¬ ë¶„ì„ â†’ ìƒì„±(ë Œë”) ìˆœìœ¼ë¡œ ì§„í–‰í•˜ì„¸ìš”.")


def run_public_mode():
    """ê¸°ì¡´ í¼ë¸”ë¦­ í™”ë©´: URL ì…ë ¥ â†’ ì´ˆì•ˆ â†’ ìˆ˜ì • â†’ ë Œë” â†’ ê³µìœ """
    left, right = st.columns([0.44, 0.56], gap="large")

    with left:
        st.subheader("ì„¸ê³„ì¼ë³´ ê¸°ì‚¬ URLë¡œ ì¸í¬ê·¸ë˜í”½ ìƒì„±")

        url = st.text_input(
            "ê¸°ì‚¬ URL (segye.com)",
            value=st.session_state.spec["meta"]["source_url"] or st.session_state.get("url", ""),
            placeholder="ì˜ˆ) https://www.segye.com/..."
        )
        url = normalize_url(url)

        btn1, btn2 = st.columns(2)
        with btn1:
            do_fetch = st.button("1) URL ë¶ˆëŸ¬ì˜¤ê¸°", use_container_width=True)
        with btn2:
            do_draft = st.button("2) ìë™ ì´ˆì•ˆ ìƒì„±", use_container_width=True)

        st.caption("â€» í˜„ì¬ëŠ” ì„¸ê³„ì¼ë³´(segye.com) ê¸°ì‚¬ë§Œ ì§€ì›í•©ë‹ˆë‹¤. ìƒì„±ë¬¼ì€ ì°¸ê³ ìš©ì´ë©° ì¶œì²˜ ë§í¬ë¥¼ í•¨ê»˜ í‘œê¸°í•©ë‹ˆë‹¤.")

        if do_fetch:
            if not url:
                st.error("ê¸°ì‚¬ URLì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
                st.stop()
            if not is_allowed_url(url):
                st.error("í˜„ì¬ëŠ” ì„¸ê³„ì¼ë³´(segye.com) ê¸°ì‚¬ë§Œ ì§€ì›í•©ë‹ˆë‹¤.")
                st.stop()

            guard_rate_limit(8)

            try:
                data = extract_article(url)

                st.session_state["url"] = data.url
                st.session_state["article_text"] = data.content
                st.session_state["og_image"] = data.og_image

                st.session_state.spec["meta"]["source_url"] = data.url
                st.session_state.spec["meta"]["title"] = data.title
                st.session_state.spec["meta"]["date"] = data.published
                st.session_state.spec["meta"]["byline"] = data.byline

                if not st.session_state.spec["content"]["headline"]:
                    st.session_state.spec["content"]["headline"] = (data.title or "").strip()

                nums = extract_numbers_with_context(data.content, max_items=20)
                st.session_state.spec["content"]["numbers_all"] = nums or []
                st.session_state.spec["content"]["numbers"] = choose_kpis(nums or [], k=4)
                st.session_state["template_hint"] = "data_focus" if len(st.session_state.spec["content"]["numbers"]) >= 2 else "story_lite"

                st.success("ê¸°ì‚¬ ì •ë³´ë¥¼ ë¶ˆëŸ¬ì™”ìŠµë‹ˆë‹¤. ë‹¤ìŒìœ¼ë¡œ 'ìë™ ì´ˆì•ˆ ìƒì„±'ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”.")
            except Exception as e:
                st.error(f"URL ë¶ˆëŸ¬ì˜¤ê¸° ì‹¤íŒ¨: {e}")

        if do_draft:
            article_text = st.session_state.get("article_text", "")
            if not article_text:
                st.warning("ë¨¼ì € 'URL ë¶ˆëŸ¬ì˜¤ê¸°'ë¥¼ ì‹¤í–‰í•´ì£¼ì„¸ìš”.")
                st.stop()

            kp = make_simple_keypoints(article_text, k=3)
            st.session_state.spec["content"]["key_points"][0]["text"] = kp[0]
            st.session_state.spec["content"]["key_points"][1]["text"] = kp[1]
            st.session_state.spec["content"]["key_points"][2]["text"] = kp[2]

            st.session_state.spec["content"]["callouts"][0]["title"] = "í•µì‹¬ ë§¥ë½"
            st.session_state.spec["content"]["callouts"][0]["body"] = make_simple_callout(article_text)

            nums_raw = extract_numbers_with_context(article_text, max_items=10)
            nums_refined = refine_numbers_with_openai(
                nums_raw,
                title_hint=st.session_state.spec["meta"].get("title", ""),
                text=article_text,
            )
            st.session_state.spec["content"]["numbers"] = nums_refined
            st.session_state["template_hint"] = "data_focus" if len(nums_refined) >= 2 else "story_lite"

            st.success("ìë™ ì´ˆì•ˆì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤. í•„ìš”í•˜ë©´ ì•„ë˜ì—ì„œ ì¼ë¶€ë§Œ ìˆ˜ì • í›„ 'ìƒì„±(ë Œë”)'ë¥¼ ëˆŒëŸ¬ì£¼ì„¸ìš”.")

        if st.button("AI ì´ˆì•ˆ ìƒì„±"):
            client = get_openai_client()
            if not client:
                st.error("API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            else:
                article_text = st.session_state.get("article_text", "")
                if not article_text:
                    st.warning("ë¨¼ì € URLì„ ë¶ˆëŸ¬ì˜¤ì„¸ìš”.")
                else:
                    with st.spinner("AIê°€ ì´ˆì•ˆì„ ìƒì„± ì¤‘ì…ë‹ˆë‹¤..."):
                        prompt = f"""
ë‹¤ìŒ ì„¸ê³„ì¼ë³´ ê¸°ì‚¬ ë‚´ìš©ì„ ì¸í¬ê·¸ë˜í”½ ì´ˆì•ˆìœ¼ë¡œ ìš”ì•½í•˜ì„¸ìš”.

í˜•ì‹:
- headline
- key_points 3ê°œ
- callout (í•µì‹¬ ë§¥ë½ 1ë¬¸ì¥)

ê¸°ì‚¬:
{article_text[:6000]}
"""
                        resp = client.chat.completions.create(
                            model="gpt-4o-mini",
                            messages=[{"role": "user", "content": prompt}],
                            temperature=0.3,
                        )
                        draft = resp.choices[0].message.content
                        st.session_state.spec["content"]["callouts"][0]["body"] = draft
                        st.success("AI ì´ˆì•ˆ ìƒì„± ì™„ë£Œ")

        with st.expander("ì¶”ì¶œëœ ìˆ«ì(ìë™) í™•ì¸", expanded=False):
            st.json(st.session_state.spec["content"].get("numbers", []))
            if st.button("ğŸ§  ë¼ë²¨ ìë™ ìƒì„±", key="label_public"):
                article_text = st.session_state.get("article_text", "")
                numbers = list(st.session_state.spec["content"].get("numbers", []))
                if not article_text:
                    st.warning("ë¨¼ì € URLì„ ë¶ˆëŸ¬ì˜¨ ë’¤ ì´ˆì•ˆì„ ìƒì„±í•˜ì„¸ìš”.")
                elif not numbers:
                    st.warning("ì¶”ì¶œëœ ìˆ«ìê°€ ì—†ìŠµë‹ˆë‹¤. ìë™ ì´ˆì•ˆ ë˜ëŠ” AI ì´ˆì•ˆì„ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”.")
                else:
                    with st.spinner("ë¼ë²¨ ìƒì„± ì¤‘..."):
                        enriched = enrich_labels(
                            st.session_state.spec["meta"].get("title", ""),
                            "",
                            article_text,
                            numbers,
                        )
                    items = enriched.get("items") or []
                    for i, n in enumerate(numbers):
                        if i < len(items) and items[i].get("label"):
                            n["label"] = (items[i].get("label") or "").strip()
                    st.session_state.spec["content"]["numbers"] = numbers
                    st.success("ë¼ë²¨ ì ìš© ì™„ë£Œ")
                    st.rerun()

        st.divider()
        st.subheader("KPI ë¼ë²¨ ìë™ ìƒì„±(AI)")
        if st.button("AIë¡œ KPI ë¼ë²¨ ì±„ìš°ê¸°", use_container_width=True, key="kpi_label_public"):
            numbers = st.session_state.spec["content"].get("numbers", [])
            if not numbers:
                st.info("ì¶”ì¶œëœ ìˆ˜ì¹˜ê°€ ì—†ìŠµë‹ˆë‹¤. (ë³¸ë¬¸ì— ìˆ«ìê°€ ì—†ê±°ë‚˜ ì¶”ì¶œ ê·œì¹™ì— ì•ˆ ì¡í˜”ì–´ìš”)")
            else:
                title = st.session_state.spec["meta"].get("title", "") or st.session_state.spec["content"].get("headline", "")
                article_text = st.session_state.get("article_text", "") or ""
                labeled = infer_kpi_labels_with_ai(
                    title=title,
                    article_text=article_text,
                    numbers=numbers,
                    publisher=st.session_state.spec["meta"].get("publisher", "ì„¸ê³„ì¼ë³´")
                )
                if labeled:
                    st.session_state.spec["content"]["numbers"] = labeled
                    st.success("KPI ë¼ë²¨ì„ ì±„ì› ìŠµë‹ˆë‹¤. (í•„ìš”í•˜ë©´ ì¼ë¶€ë§Œ ìˆ˜ì • í›„ ë Œë”í•˜ì„¸ìš”.)")
                    st.session_state.dirty = True
                else:
                    st.info("AI ë¼ë²¨ ìƒì„± ê²°ê³¼ê°€ ì—†ê±°ë‚˜ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. (API í‚¤/ë³¸ë¬¸/ìˆ«ì ì¶”ì¶œì„ í™•ì¸)")

        with st.expander("ìˆ˜ì •(ì„ íƒ) â€” í—¤ë“œë¼ì¸/í‚¤í¬ì¸íŠ¸ë§Œ ë‹¤ë“¬ê¸°", expanded=False):
            title = st.text_input("ì œëª©(ì›ë¬¸)", value=st.session_state.spec["meta"]["title"])
            date = st.text_input("ë‚ ì§œ", value=st.session_state.spec["meta"]["date"])
            byline = st.text_input("ë°”ì´ë¼ì¸", value=st.session_state.spec["meta"]["byline"])

            st.divider()
            headline = st.text_input("í—¤ë“œë¼ì¸(ì¸í¬ê·¸ë˜í”½ìš©)", value=st.session_state.spec["content"]["headline"])
            dek = st.text_input("ì„œë¸Œ ë¬¸ì¥(ì„ íƒ)", value=st.session_state.spec["content"]["dek"])

            st.write("í•µì‹¬ í¬ì¸íŠ¸(3ê°œ)")
            kp1 = st.text_area("1", value=st.session_state.spec["content"]["key_points"][0]["text"], height=72)
            kp2 = st.text_area("2", value=st.session_state.spec["content"]["key_points"][1]["text"], height=72)
            kp3 = st.text_area("3", value=st.session_state.spec["content"]["key_points"][2]["text"], height=72)

            st.write("ì½œì•„ì›ƒ(ìš”ì•½ ê¸°ë°˜ì¼ ë•Œ í•µì‹¬ ë§¥ë½ 1ê°œ)")
            callout_title = st.text_input("ì½œì•„ì›ƒ ì œëª©", value=st.session_state.spec["content"]["callouts"][0]["title"])
            callout_body = st.text_area("ì½œì•„ì›ƒ ë³¸ë¬¸", value=st.session_state.spec["content"]["callouts"][0]["body"], height=90)

            st.write("ì¸ìš©(ê¸°ì‚¬ì— ìˆì„ ë•Œë§Œ)")
            q_text = st.text_area("ì¸ìš©ë¬¸", value=st.session_state.spec["content"]["quote"]["text"], height=80)

            _opts = ["story_lite", "data_focus", "timeline", "compare"]
            default_tpl = st.session_state.get("template_hint", "story_lite")
            template = st.radio(
                "í…œí”Œë¦¿",
                options=_opts,
                index=_opts.index(default_tpl) if default_tpl in _opts else 0,
                horizontal=True
            )
            st.session_state["template"] = template

        c1, c2 = st.columns(2)
        with c1:
            if st.button("ì €ì¥(í™•ì¸)"):
                st.session_state.spec["meta"]["source_url"] = url
                st.session_state.spec["meta"]["title"] = title
                st.session_state.spec["meta"]["date"] = date
                st.session_state.spec["meta"]["byline"] = byline

                st.session_state.spec["content"]["headline"] = headline
                st.session_state.spec["content"]["dek"] = dek

                st.session_state.spec["content"]["key_points"][0]["text"] = kp1.strip()
                st.session_state.spec["content"]["key_points"][1]["text"] = kp2.strip()
                st.session_state.spec["content"]["key_points"][2]["text"] = kp3.strip()

                st.session_state.spec["content"]["callouts"][0]["title"] = callout_title.strip()
                st.session_state.spec["content"]["callouts"][0]["body"] = callout_body.strip()

                st.session_state.spec["content"]["quote"]["text"] = q_text.strip()

                pub = st.session_state.spec["meta"].get("publisher","ì„¸ê³„ì¼ë³´")
                st.session_state.spec["content"]["sources"] = [{"name": pub, "detail": url}]
                st.session_state.dirty = True

        with c2:
            if st.button("ìƒì„±(ë Œë”)"):
                st.session_state.spec["layout"] = choose_layout(st.session_state.spec)
                rm = build_render_model(st.session_state.spec)
                tpl_key = st.session_state.get("template") or st.session_state.get("template_hint") or "story_lite"
                st.session_state.svg = render_svg(tpl_key, rm)
                st.session_state.dirty = False

        st.caption(f"ìƒíƒœ: {'ìˆ˜ì •ë¨(ë¯¸ë°˜ì˜)' if st.session_state.dirty else 'ìµœì‹  ë°˜ì˜ë¨'}")

        with st.expander("Spec JSON ë³´ê¸°"):
            st.code(json.dumps(st.session_state.spec, ensure_ascii=False, indent=2), language="json")

    with right:
        st.subheader("ë¯¸ë¦¬ë³´ê¸°(ê³ ì •)")
        if st.session_state.svg:
            st.components.v1.html(st.session_state.svg, height=1120, scrolling=True)

            encoded = base64.urlsafe_b64encode(st.session_state.svg.encode()).decode()
            share_url = f"https://segye-on.streamlit.app/?share={encoded}"

            st.markdown("### ê³µìœ ")
            st.code(share_url)
            st.link_button("ì¹´ì¹´ì˜¤í†¡ ê³µìœ ", f"https://share.kakao.com/?url={share_url}")
            st.link_button("íŠ¸ìœ„í„° ê³µìœ ", f"https://twitter.com/intent/tweet?url={share_url}")

            st.download_button(
                label="SVG ë‹¤ìš´ë¡œë“œ",
                data=st.session_state.svg.encode("utf-8"),
                file_name="segye_infographic.svg",
                mime="image/svg+xml"
            )

            try:
                import cairosvg
                safe_svg = sanitize_svg_for_png(st.session_state.svg)
                safe_svg = strip_css_import(safe_svg)
                safe_svg = svg_fonts_to_absolute_paths(safe_svg)
                png_bytes = cairosvg.svg2png(bytestring=safe_svg.encode("utf-8"))
                st.download_button(
                    label="PNG ë‹¤ìš´ë¡œë“œ",
                    data=png_bytes,
                    file_name="segye_infographic.png",
                    mime="image/png"
                )
            except Exception as e:
                st.warning(f"PNG ë³€í™˜ ì‹¤íŒ¨: {e}")
                lines = (st.session_state.svg or "").splitlines()
                if len(lines) >= 6:
                    st.caption("ë””ë²„ê·¸: SVG ìƒë‹¨ 8ì¤„")
                    st.code("\n".join(lines[:8]))

        else:
            st.info("ì¢Œì¸¡ì—ì„œ ì…ë ¥/ìˆ˜ì • í›„ 'ìƒì„±(ë Œë”)'ë¥¼ ëˆ„ë¥´ë©´ ì—¬ê¸°ì—ì„œ ê²°ê³¼ë¥¼ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")


desk = is_desk_mode()
if desk:
    if not desk_auth_ok():
        st.stop()
    run_desk_mode()
else:
    run_public_mode()
